{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9168675,"sourceType":"datasetVersion","datasetId":5540295}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport threading\nimport xml.etree.ElementTree as ET\nfrom scipy.signal import savgol_filter\nfrom scipy.interpolate import CubicSpline\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, Model\nfrom tensorflow.keras.losses import CategoricalCrossentropy, KLDivergence\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import KMeans\nimport cv2 as cv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VECTOR_START = 7\nVECTOR_END = 115\nRELATIVE_BAND_WITH_1500_WAVELENGTH = 48-VECTOR_START\nWINDOW_SIZE = 7\nPOLY_ORDER = 2\nD_AU = 1\n\nF0 = np.array([136.1259307, 129.8781929, 125.1457188, 120.4566749, 115.2187742, 110.7989129, 105.971862, 102.2853476, 98.83159112, 95.00990644, 91.72241746, 88.63043389, 85.44216416, 83.09659958, 80.7461688, 77.99745659, 75.43755054, 72.53298554, 70.30310472, 67.71506702, 65.53063581, 63.51647332, 61.49193881, 59.39769145, 57.24811211, 55.56974549, 53.96628612, 52.39858882, 50.94286582, 49.55873832, 47.99340839, 46.35543865, 45.11640663, 43.75374359, 42.46741487, 41.1950428, 39.93375405, 38.7480202, 37.63257797, 36.52968828, 35.48372942, 34.51571377, 33.5041102, 32.62925225, 31.80035805, 30.98128654, 30.16775831, 29.32709974, 28.56074168, 27.8298174, 27.0453247, 26.30808675, 25.51810387, 24.75010497, 24.00573968, 23.24760491, 22.51761852, 21.78398871, 21.06792047, 20.39822233, 19.7458807, 19.11661541, 18.44061437, 17.83250529, 17.26068394, 16.65126453, 16.11545704, 15.61912435, 15.1210474, 14.62910738, 14.16359209, 13.72237684, 13.31430194, 12.94713935, 12.56233275, 12.18239943, 11.79722098, 11.38810049, 11.04636914, 10.71621297, 10.38904988, 10.06620698, 9.753295821, 9.46418631, 9.201075776, 8.960974818, 8.732115834, 8.508712424, 8.28861478, 8.070068082, 7.850866176, 7.629585176, 7.417896212, 7.21399149, 7.014245694, 6.819995994, 6.637200746, 6.463212542, 6.291676014, 6.122400975, 5.952327234, 5.785907458, 5.631916792, 5.48221029, 5.338864421, 5.183886388, 5.053359936, 4.941756508, 4.835098184, 4.719922707, 4.619729215, 4.511137419, 4.407240202, 4.306184976, 4.210413629, 4.117013411, 4.012368768, 3.918726643, 3.824014432, 3.725826304, 3.646586732, 3.564719937, 3.488199195, 3.397463341, 3.32250234, 3.262984894, 3.190955311, 3.122692223, 3.056477464, 2.991274348, 2.926566072, 2.864612339, 2.802940836, 2.743157021, 2.685370618, 2.628641884, 2.571929704, 2.517226294, 2.465127643, 2.414375576, 2.365285234, 2.316701141, 2.26923212, 2.222564505, 2.178496705, 2.135290025, 2.092826765, 2.051565701, 2.010893773, 1.971470582, 1.932492639, 1.893925453, 1.853239032, 1.814419696, 1.780829606, 1.751599126, 1.715922793, 1.680125966, 1.647791753, 1.621454182, 1.593640531, 1.560460708, 1.532378246, 1.507178355, 1.480349348, 1.454525518, 1.426003985, 1.40026592, 1.376814112, 1.351395724, 1.327241488, 1.303320437, 1.279240078, 1.255715058, 1.232621586, 1.209534773, 1.186777237, 1.163774025, 1.141839466, 1.121354795, 1.102697582, 1.084984542, 1.06779729, 1.050654559, 1.034116451, 1.018239678, 1.003106371, 0.987228033, 0.971082552, 0.954532246, 0.938549781, 0.922761605, 0.90746215, 0.892772367, 0.876952832, 0.86169586, 0.846904043, 0.832961745, 0.820193322, 0.808495532, 0.796418017, 0.784036511, 0.771772032, 0.760169612, 0.74902997, 0.737997332, 0.727055348, 0.716477866, 0.704633464, 0.691770452, 0.681177697, 0.668685204, 0.6563386, 0.643784606, 0.630929839, 0.618670348, 0.605670184, 0.593191697, 0.582320158, 0.571630629, 0.561438106, 0.551831735, 0.542986524, 0.534529199, 0.526707332, 0.518722109, 0.511109087, 0.50373316, 0.496221855, 0.489530981, 0.482582186, 0.475974536, 0.469794569, 0.463575699, 0.458286546, 0.452850271, 0.447197638, 0.441572082, 0.43580287, 0.430755766, 0.425717099, 0.420589447, 0.41588213, 0.410468477, 0.405233536, 0.399887123, 0.394668014, 0.389642973, 0.384580319, 0.379611238, 0.374544041, 0.369613524, 0.364863435, 0.360132602, 0.355533758, 0.350967069]\n).reshape(256,1,1)\n\nTARGET_WAVELENGTHS = target_wavelengths = np.array([\n    796.6, 813.4, 830.3, 847.2, 864.0, 880.9, 897.7, 914.6, 931.4, 948.3,\n    965.1, 982.0, 998.8, 1015.7, 1032.5, 1049.4, 1066.2, 1083.1, 1099.9, 1116.8,\n    1133.6, 1150.5, 1167.3, 1184.2, 1201.1, 1217.9, 1234.8, 1251.6, 1268.5, 1285.3,\n    1302.2, 1319.0, 1335.9, 1352.7, 1369.6, 1386.4, 1403.3, 1420.1, 1437.0, 1453.8,\n    1470.7, 1487.5, 1504.4, 1521.2, 1538.1, 1555.0, 1571.8, 1588.7, 1605.5, 1622.4,\n    1639.2, 1656.1, 1672.9, 1689.8, 1706.6, 1723.5, 1740.3, 1757.2, 1774.0, 1790.9,\n    1807.7, 1824.6, 1841.4, 1858.3, 1875.1, 1892.0, 1908.9, 1925.7, 1942.6, 1959.4,\n    1976.3, 1993.1, 2010.0, 2026.8, 2043.7, 2060.5, 2077.4, 2094.2, 2111.1, 2127.9,\n    2144.8, 2161.6, 2178.5, 2195.3, 2212.2, 2229.0, 2245.9, 2262.8, 2279.6, 2296.5,\n    2313.3, 2330.2, 2347.0, 2363.9, 2380.7, 2397.6, 2414.4, 2431.3, 2448.1, 2465.0,\n    2481.8, 2498.7, 2515.5, 2532.4, 2549.2, 2566.1, 2582.9, 2599.8, 2616.7\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_xml_file(xml_file_path):\n    \"\"\"\n        Helper function: Reads and extarct useful information from the xml file.\n        Args-> XML file path\n        Returns -> image shape, gain, exposure\n    \"\"\"\n    \n    tree = ET.parse(xml_file_path)\n    root = tree.getroot()\n    axis_elements = {}\n    namespaces = {\n        'ns': 'http://pds.nasa.gov/pds4/pds/v1'\n    }\n\n    namespaces_exposure_gain = {\n        'isda': 'https://isda.issdc.gov.in/pds4/isda/v1'\n    }\n\n    for axis_array in root.findall('.//ns:Axis_Array', namespaces):        \n        axis_name_element = axis_array.find('ns:axis_name', namespaces)\n        if axis_name_element is not None:\n            axis_name = axis_name_element.text.strip()\n        else:\n            print(\"Warning: 'axis_name' tag is missing.\")\n            continue\n\n        elements_element = axis_array.find('ns:elements', namespaces)\n        if elements_element is not None:\n            try:\n                elements = int(elements_element.text.strip())\n            except ValueError:\n                print(f\"Error: 'elements' value is not a valid integer.\")\n                continue\n        else:\n            print(f\"Warning: 'elements' tag is missing.\")\n            continue\n        axis_elements[axis_name] = elements\n\n    gain = root.find('.//isda:gain', namespaces_exposure_gain).text\n    exposure = root.find('.//isda:exposure', namespaces_exposure_gain).text\n\n    return (256, axis_elements.get('LINE', 0), axis_elements.get('SAMPLE', 0)), exposure, gain\n\ndef read_image(data_folder_path):\n    \"\"\"\n        Reading the images from disk: The function here uses the directory structure to extract the image_file from .qub file into a numpy array.\n        Args -> data_folder_path : str, IMAGE_NAME/data/calibrated/.../\n        Returns -> Image object\n    \"\"\"\n    def convert_to_reflectance(image, solar_zenith_angle=45):\n        return (np.pi * image)/(np.cos(solar_zenith_angle * np.pi / 180) * F0 * D_AU**2)\n    image_shape=None\n    image=-1\n    for _file in os.listdir(data_folder_path):\n        if _file[-4:] == \".xml\":\n            image_shape, _, _ = read_xml_file(os.path.join(data_folder_path, _file))\n        elif _file[-4:] == \".qub\":\n            with open(os.path.join(data_folder_path, _file), 'rb') as f:\n                image = np.reshape(np.frombuffer(f.read(), dtype=np.float32), newshape=image_shape) \n                break\n                \n    else:\n        return -1\n\n    return convert_to_reflectance(image)\n\ndef extract_pixel_arrays(image):\n    \"\"\"\n        Extract pixel arrays: Used to extract the pixels in an array to run the functions on.\n        Args -> Image cube : np.ndarray\n        Returns -> 2D array of each pixel with its corresponding array across axis=-1\n    \"\"\"\n    pixel_values = []\n    for i in range(image.shape[1]):\n        for j in range(image.shape[2]):\n            pixel_values.append(image[VECTOR_START:VECTOR_END, i, j])\n\n    return np.asarray(pixel_values, dtype=np.float32)\n\ndef normalize_pixel_arrays(pixel_vector_array):\n    \"\"\"\n        Normalization: Takes in a pixel array and normalizes the array wrt _lambda = 1500nm. This value is chosen because there are no absorption drops in this region.\n        Args -> 2D array of pixel vectors, image_normalization_value cube.\n        Return -> 2D array of normalized pixel_vectors\n    \"\"\"\n    for i in range(pixel_vector_array.shape[0]):\n        pixel_vector_array[i] = pixel_vector_array[i]/pixel_vector_array[i][RELATIVE_BAND_WITH_1500_WAVELENGTH]\n\n    return pixel_vector_array\n\ndef denoising_pixel_arrays(pixel_values, window_size=WINDOW_SIZE, polyorder=POLY_ORDER, axis=-1):\n    \"\"\"\n        Denoising: Takes in a pixel array and runs Savinsky_Golay filter on pixel array axis.\n        Args -> 2D array of pixel values, window_size, polynomial order, axis\n        Return -> Smoothened 2D array of pixel values\n    \"\"\"\n    return savgol_filter(pixel_values, window_length=window_size, polyorder=polyorder, axis=axis)\n\ndef interpolate_osf_bands(data_folder_path, pixel_values):\n    \"\"\"\n        Interpolating OSF bands: Removes overlap in the file and interpolates lost data back\n        Args -> 2D array of pixel vectors, data_folder_path\n        Return -> 2D array of normalized pixel_vectors\n    \"\"\"\n    for _file in os.listdir(data_folder_path):\n        if _file[-4:] == \".xml\":\n            _, exposure, gain = read_xml_file(os.path.join(data_folder_path, _file))\n\n    if exposure+gain == \"e1g2\" or exposure+gain==\"e2g2\" or exposure+gain==\"e3g2\":\n        combined_array = np.concatenate((pixel_values[:, VECTOR_START:29], pixel_values[:,35:69], pixel_values[:, 76:VECTOR_END]), axis=-1)\n        original_idx = np.concatenate([np.arange(VECTOR_START, 29), np.arange(35,69), np.arange(76, VECTOR_END)])\n        interpolated_idx = np.arange(VECTOR_START, VECTOR_END)\n\n        cubic_spline = CubicSpline(original_idx, combined_array)\n        return cubic_spline(interpolated_idx)\n    \n    else:\n        raise ValueError(\"E4G2 is not a valid sensor configuration for this software.\")\n    \ndef main(image_folder_path_that_has_4_sub_folders):\n    data_folder_path_before_files = os.path.join(image_folder_path_that_has_4_sub_folders, \"data/calibrated/\")\n    data_folder_path_files = os.path.join(data_folder_path_before_files, os.listdir(data_folder_path_before_files)[0])\n\n    image = read_image(data_folder_path_files)\n    if isinstance(image,int):\n        return -1\n    try:\n        pixel_values = interpolate_osf_bands(data_folder_path_files, denoising_pixel_arrays(normalize_pixel_arrays(extract_pixel_arrays(image))))\n    except:\n        \"Couldn't interpolate OSF.\"\n        pixel_values = denoising_pixel_arrays(normalize_pixel_arrays(extract_pixel_arrays(image)))\n\n    return pixel_values\n\ndef process_into_array(input_path, output_path):\n    try:\n        dataset = np.load(output_path)\n    except:\n        np.save(output_path, np.zeros((1, VECTOR_END-VECTOR_START), dtype=np.float32))\n        \n    dataset = np.vstack((dataset, main))\n    np.save(output_path, dataset)\n    del dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1,4):\n    INPUT = f\"/kaggle/input/iirs-train-test-dataset/DATASET_NEW/moon_site_{i}/train\"\n    OUTPUT = r\"/kaggle/working/pixel_vector_data_train_files_transformed.npy\"\n\n    for _folder in os.listdit(INPUT):\n        process_into_array(os.path.join(INPUT, _folder), OUTPUT)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CLUSTERING**","metadata":{}},{"cell_type":"markdown","source":"## VaDE","metadata":{}},{"cell_type":"code","source":"class VAE(tf.keras.Model):\n    def __init__(self, input_dim, hidden_dim, latent_dim):\n        super(VAE, self).__init__()\n        self.latent_dim = latent_dim\n        \n        # Encoder\n        self.encoder = models.Sequential([\n            layers.InputLayer(input_shape=(input_dim,)),\n            layers.Dense(hidden_dim*2, activation=tf.nn.gelu),\n            layers.Dense(hidden_dim, activation=tf.nn.tanh),\n            layers.Dense(hidden_dim//2, activation=tf.nn.gelu),\n            layers.Dense(2 * latent_dim)  # Output both mean and log variance\n        ])\n        \n        # Decoder\n        self.decoder = models.Sequential([\n            layers.InputLayer(input_shape=(latent_dim,)),\n            layers.Dense(hidden_dim//2, activation=tf.nn.gelu),\n            layers.Dense(hidden_dim, activation=tf.nn.tanh),\n            layers.Dense(hidden_dim*2, activation=tf.nn.gelu),\n            layers.Dense(input_dim, activation=tf.nn.sigmoid)\n        ])\n    \n    def encode(self, x):\n        h = self.encoder(x)\n        # mu, var are mean and variance respectively\n        mu, logvar = tf.split(h, num_or_size_splits=2, axis=1)\n        return mu, logvar\n    \n    def reparameterize(self, mu, logvar):\n        std = tf.exp(0.5 * logvar)\n        eps = tf.random.normal(shape=tf.shape(std))\n        return mu + eps * std\n    \n    def decode(self, z):\n        return self.decoder(z)\n    \n    def call(self, inputs):\n        mu, logvar = self.encode(inputs)\n        z = self.reparameterize(mu, logvar)\n        reconstructed = self.decode(z)\n        return reconstructed, mu, logvar, z\n    \nclass GMM(tf.keras.layers.Layer):\n    def __init__(self, n_clusters, latent_dim):\n        super(GMM, self).__init__()\n        self.n_clusters = n_clusters\n        self.latent_dim = latent_dim\n        \n        # GMM parameters\n        self.pi = self.add_weight(shape=(n_clusters,), initializer='uniform', trainable=True)\n        self.mu_c = self.add_weight(shape=(n_clusters, latent_dim), initializer='random_normal', trainable=True)\n        self.logvar_c = self.add_weight(shape=(n_clusters, latent_dim), initializer='random_normal', trainable=True)\n    \n    def call(self, z):\n        z_expand = tf.expand_dims(z, 1)\n        mu_expand = tf.expand_dims(self.mu_c, 0)\n        logvar_expand = tf.expand_dims(self.logvar_c, 0)\n        \n        log_probs = -0.5 * (logvar_expand + (z_expand - mu_expand) ** 2 / tf.exp(logvar_expand))\n        log_probs = tf.reduce_sum(log_probs, axis=2)\n        log_probs = log_probs + tf.math.log(self.pi)\n        log_probs = tf.nn.log_softmax(log_probs, axis=1)\n        \n        return log_probs\n    \nclass VaDE(tf.keras.Model):\n    def __init__(self, input_dim, hidden_dim, latent_dim, n_clusters):\n        super(VaDE, self).__init__()\n        self.vae = VAE(input_dim, hidden_dim, latent_dim)\n        self.gmm = GMM(n_clusters, latent_dim)\n    \n    def call(self, inputs):\n        reconstructed, mu, logvar, z = self.vae(inputs)\n        log_probs = self.gmm(z)\n        return reconstructed, mu, logvar, z, log_probs\n    \n    def compute_loss(self, x, reconstructed, mu, logvar, z, log_probs):\n        recon_loss = tf.reduce_sum(losses.binary_crossentropy(x, reconstructed))\n        kl_div = -0.5 * tf.reduce_sum(1 + logvar - tf.square(mu) - tf.exp(logvar))\n        kl_gmm = -tf.reduce_sum(tf.reduce_sum(log_probs * tf.exp(log_probs), axis=1))\n        \n        return recon_loss + kl_div + kl_gmm\n\n\ndef train_vade(model, data, epochs, batch_size, learning_rate):\n    optimizer = tf.keras.optimizers.Adam(learning_rate)\n    \n    dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(buffer_size=1024).batch(batch_size)\n    \n    for epoch in range(epochs):\n        epoch_loss = 0\n        for batch in dataset:\n            with tf.GradientTape() as tape:\n                reconstructed, mu, logvar, z, log_probs = model(batch)\n                loss = model.compute_loss(batch, reconstructed, mu, logvar, z, log_probs)\n            grads = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n            epoch_loss += loss.numpy()\n        \n        print(f'Epoch {epoch+1}, Loss: {epoch_loss / len(data):.4f}')\n\ndef cluster_data(model, data):\n    _, _, _, _, log_probs = model(data)\n    clusters = tf.argmax(log_probs, axis=1)\n    return clusters.numpy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ARRAY_PATH = r\"/kaggle/working/pixel_vector_data_train_files_transformed.npy\"\nNUM_CLUSTERS = 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dimension = VECTOR_END-VECTOR_START\nhidden_dimension = 128\nlatent_dimension = 32\nn_clusters = NUM_CLUSTERS\n\nX = np.load(ARRAY_PATH)\n\nvade_model = VaDE(input_dimension, hidden_dimension, latent_dimension, n_clusters)\nvade_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_vade(vade_model, X, epochs=20, batch_size=128, learning_rate=3e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-Means","metadata":{}},{"cell_type":"code","source":"def init_k_means(num_clusters, init, max_iters, random_state=69):\n    return KMeans(n_clusters=num_clusters, init=init, max_iter=max_iters, random_state=random_state)\n\ndef run_k_means(model, input_array):\n    model.fit(input_array)\n    return model.labels_, model.cluster_centers_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INIT = \"k-means++\"\nMAX_ITERS = 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_k_means = init_k_means(NUM_CLUSTERS, INIT, MAX_ITERS)\nlabels, clusters_centers = run_k_means(model_k_means, X)\n\nprint(f\"{labels.shape}\\n{clusters_centers.shape}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **CNN**","metadata":{}},{"cell_type":"code","source":"NUM_CLASSES = 163\nNUM_EPOCHS = 30","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def match_spectrums(pixel_arrays, look_up_table, ground_truth_for_cnn_path, y):\n    def similarity_algorithm(sample_array_1, sample_array_2):    \n        def CPRMS(pixel_vector, reference_vector):\n            mean_pixel = np.mean(pixel_vector)\n            mean_reference = np.mean(reference_vector)\n            centered_pixel = pixel_vector - mean_pixel\n            centered_reference = reference_vector - mean_reference\n            squared_diff = (centered_pixel - centered_reference) ** 2\n            val = np.sqrt(np.mean(squared_diff))\n            \n            return val\n\n        def ABS(f_n, r_n):\n            return np.sum(np.abs(f_n - r_n))\n\n        return CPRMS(sample_array_1, sample_array_2) + 100*ABS(sample_array_1, sample_array_2)\n\n    \n    for i in range(pixel_arrays.shape[0]):\n        similarity_vector = np.zeros((NUM_CLASSES,), dtype=np.float32)\n        for j in range(look_up_table.shape[0]):\n            similarity_vector[j] = similarity_algorithm(pixel_arrays[i], look_up_table[j])\n\n        y = np.vstack((y,similarity_vector))\n        np.save(ground_truth_for_cnn_path, y)\n\n    return\n\ndef plot_spectra_in_pixel_array(pixel_arrays, output_path):\n    for i in range(pixel_arrays.shape[0]):\n        _ = plt.figure(figsize=(50, 30))\n        plt.plot(pixel_arrays[i], color=\"orange\")\n        plt.axes('off')\n        plt.savefig(os.path.join(output_path, f\"{i}.png\"))\n\n\ndef cnn_model(input_shape):\n    def hybrid_pooling(_input, pool_size=(2, 2)):\n        avg_pool = layers.AveragePooling2D(pool_size=pool_size, padding=\"same\", strides=(1,1))(_input)\n        max_pool = layers.MaxPooling2D(pool_size=pool_size, padding=\"same\", strides=(1,1))(_input)\n        return layers.Concatenate()([avg_pool, max_pool])\n\n    def inception_block(_input, num_filter):\n        x1 = layers.Conv2D(num_filter, (1,1), activation=tf.nn.gelu, padding=\"same\")(_input)\n        x2 = layers.Conv2D(num_filter, (3,3), activation=tf.nn.gelu, padding=\"same\")(_input)\n        x3 = layers.Conv2D(num_filter, (5,5), activation=tf.nn.gelu, padding=\"same\")(_input)\n        x4 = hybrid_pooling(_input=_input)\n        x4 = layers.Conv2D(num_filter, (1,1), activation=tf.nn.gelu, padding=\"same\")(x4)\n        output_for_inception_block = layers.Concatenate()([x1,x2,x3,x4])\n        return output_for_inception_block\n\n    _inputs = layers.Input(shape=input_shape)\n    x1 = layers.Conv2D(16, (1,1), activation=tf.nn.gelu, padding=\"same\")(_inputs)\n    x2 = layers.Conv2D(16, (3,3), activation=tf.nn.gelu, padding=\"same\")(_inputs)\n    x3 = layers.Conv2D(16, (5,5), activation=tf.nn.gelu, padding=\"same\")(_inputs)\n    x4 = hybrid_pooling(_input=_inputs)\n    x = layers.Concatenate()([x1,x2,x3,x4])\n\n    x = layers.Dropout(0.3)\n    \n    x = inception_block(x, 32)\n    x = hybrid_pooling(x)\n\n    x = layers.Dropout(0.3)\n    \n    x = inception_block(x, 16)\n    x = hybrid_pooling(x)\n\n    x = layers.Flatten()(x)\n    x = layers.Dense(32, activation=tf.nn.gelu, kernel_regularizer=tf.keras.Regularizer.L2(0.03))(x)\n    x = layers.Dense(64, activation=tf.nn.gelu, kernel_regularizer=tf.keras.Regularizer.L2(0.01))(x)\n    _outputs = layers.Dense(NUM_CLASSES, activation=tf.nn.softmax)(x)\n\n    model = Model(_inputs, _outputs)\n    return model\n\ndef custom_loss_function(y_true, y_pred):\n    kl_loss = KLDivergence()(y_true, y_pred)\n    categorical_loss = CategoricalCrossentropy()(y_true, y_pred)\n\n    return 0.4*kl_loss+0.6*categorical_loss\n\ndef create_X_for_model(path_to_spectral_images):\n    X = []\n    for _file in os.listdir(path_to_spectral_images):\n        X.append(cv.imread(os.path.join(path_to_spectral_images, _file)))\n\n    return X\n\ndef create_y_for_model(path_to_spectral_mapping_to_table):\n    y = []\n    for _file in os.listdir(path_to_spectral_mapping_to_table):\n        y.append(cv.imread(os.path.join(path_to_spectral_mapping_to_table, _file)))\n\n    return y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PIXEL_ARRAY_PATH = None\nSPECTRAL_IMAGES_PATH = None\nSPECTRAL_MAPPING_PATH = None","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    y = np.load(SPECTRAL_MAPPING_PATH)\nexcept:\n    np.save(SPECTRAL_MAPPING_PATH, np.zeros((NUM_CLASSES,), dtype=np.float32))\n    y = np.load(SPECTRAL_MAPPING_PATH)\n\ndel y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pixel_arrays = np.load(PIXEL_ARRAY_PATH)\nplot_spectra_in_pixel_array(pixel_arrays, SPECTRAL_IMAGES_PATH)\n\n# X and y for model training\nX = create_X_for_model(SPECTRAL_IMAGES_PATH)\ny = create_y_for_model(SPECTRAL_MAPPING_PATH)\n\n# CNN model instantiate\ncnn = cnn_model(input_shape=X[0].shape)\ncnn.compile(optimizer=tf.keras.optimizers.AdamW, loss=custom_loss_function, metrics=['accuracy'])\nat_training = cnn.fit(X, y, epochs=30, validation_split=0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **GARBAGE**","metadata":{}},{"cell_type":"code","source":"\"\"\"all_paths = []\ndataset = None\nsolved = 1\n\nINPUT_PATH = \"/kaggle/input/iirs-train-test-dataset/DATASET_NEW\"\nOUTPUT_PATH = \"/kaggle/working/pixel_vector_data_train_files_transformed.npy\"\n\ntry:\n    dataset = np.load(OUTPUT_PATH)\nexcept:\n    np.save(OUTPUT_PATH, np.zeros((1, VECTOR_END-VECTOR_START), dtype=np.float32))\n    dataset = np.load(OUTPUT_PATH)\n    \ni = 1\nfor moon_site in os.listdir(INPUT_PATH):\n    for _folders in os.listdir(os.path.join(INPUT_PATH, moon_site)):\n        if _folders == \"train\":\n            for image_folder in os.listdir(os.path.join(INPUT_PATH, moon_site, _folders)):\n                all_paths.append((i, os.path.join(INPUT_PATH, moon_site, _folders, image_folder)))\n                i += 1\n    break\n    \nall_paths = sorted(all_paths)\n\nthreads = []\n\ndef solve(index, path):\n    global solved, dataset\n\n    current = main(path)\n    if current == -1:\n        solved.append(index)\n        print(f\"{index} : Skipped: {path}\")\n\n    else:\n        print(f\"{index} Processed\")\n        while (True):\n            if (index-1 in solved and len(solved) >= index):\n                break\n            \n            continue\n        \n        dataset = np.vstack((dataset, current))\n        np.save(OUTPUT_PATH, dataset)\n        solved.append(index)\n        \n        print(f\"{index} : Done for: {path}\")\n\n\nfor index_path in all_paths:    \n    t = threading.Thread(target=solve, args=(index_path[0], index_path[1]))\n    t.start()\n    threads.append(t)\n\nfor t in threads:\n    t.join()\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}